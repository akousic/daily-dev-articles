# OpenAI and Google Take Steps to Avoid Abusive AI Imagery After Grok Scandal https://t.co/fCDBfBsRd7

- **Source:** X
- **Rank (today):** #8
- **Ranking metrics:** likes 0, reposts 0, replies 0, quotes 0, score 0
- **Published (UTC):** 2026-02-24 20:51
- **Original:** https://cnet.co/3P0nO91
- **X post:** https://x.com/CNETNews/status/2026399588588949942
- **Posted by:** @CNETNews

## Summary

2026 started with a horrifying example of generative AI's potential for abuse. Grok, the AI tool from Elon Musk's xAI, was used to undress or nudify pictures of people shared on X (formerly Twitter) at an alarming rate. Grok made 3 million sexualized images over a span of 11 days in January, with approximately 23,000 of those containing images of children, according to a study from the Center for Countering Digital Hate.

## Key Takeaways

- Now, competitors like OpenAI and Google are stepping up their security to avoid being the next Grok.
- Advocates and safety researchers have long been concerned about AI's ability to create abusive and illegal content.
- The creation and sharing of nonconsensual intimate imagery, sometimes referred to as revenge porn, was a big problem before AI.

---
_Auto-generated daily digest entry._
